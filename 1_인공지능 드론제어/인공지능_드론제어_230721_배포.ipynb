{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tello Talent Python Control with AI\n",
    "\n",
    "230721, by wygo\n",
    "\n",
    "- [ref](https://github.com/damiafuentes/DJITelloPy)\n",
    "- [ref](https://github.com/dji-sdk/Tello-Python)\n",
    "\n",
    "- error 해결\n",
    "    - 'error Not joystick' 에러가 나면 **kernel** -> **Restart & Clear Output** 누른 후 다시 실행\n",
    "    - 충전할 땐 불이 들어오는데, 충전잭을 뽑고 전원을 눌렀을 때 전원이 안들어 오는 경우-> 배터리 수명끝. 새 배터리로 교체\n",
    "    - 'KeyError: '192.168.10.1'' 에러가 나는 경우, 한번 더 실행(shift+enter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1) Setting\n",
    "\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.5.2.52 in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (from opencv-python==4.5.2.52) (1.21.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python==4.5.2.52 in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (from opencv-contrib-python==4.5.2.52) (1.21.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils==0.5.4 in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (0.5.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: djitellopy in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (from djitellopy) (9.3.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (from djitellopy) (4.5.2.52)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (from djitellopy) (1.21.6)\n",
      "Requirement already satisfied: av in c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages (from djitellopy) (10.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user\\anaconda3\\envs\\venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "## install\n",
    "# install with requirements.txt\n",
    "import os\n",
    "if os.path.isfile('requirements.txt'):\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    !pip install opencv-python==4.5.2.52\n",
    "    !pip install opencv-contrib-python==4.5.2.52\n",
    "    !pip install imutils==0.5.4\n",
    "    !pip install djitellopy\n",
    "    !pip install mediapipe==0.9.0.1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1.1) install\n",
    "    - 1.1.1) Install using pip\n",
    "        >> pip install djitellopy\n",
    "    - 1.1.2) Install in developer mode\n",
    "        >> git clone https://github.com/damiafuentes/DJITelloPy.git\n",
    "        >> cd DJITelloPy\n",
    "        >> pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1.2) Test installation\n",
    "\n",
    "- [ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/00_test_installation.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your installation worked!\n"
     ]
    }
   ],
   "source": [
    "## test installation\n",
    "from djitellopy import Tello\n",
    "import cv2\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "print(\"Your installation worked!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1.3) 기본 동작 테스트\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/01_takeoff-land.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 01_takeoff-land.py\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()\n",
    "\n",
    "print(\"Sleep for 5 seconds\")\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1.4) TT 상태 받아오기\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/01_takeoff-land.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## bonus_01_get_tello_state.py\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()  # 이륙\n",
    "\n",
    "print(\"Get entire Tello Current State\")\n",
    "# {'pitch': 0, 'roll': 0, 'yaw': 29, 'vgx': 0, 'vgy': 0, 'vgz': 0, 'templ': 76, 'temph': 78, 'tof': 72, 'h': -10, 'bat': 67, 'baro': 235.23, 'time': 38, 'agx': -22.0, 'agy': -15.0, 'agz': -1059.0}\n",
    "tello_state = tello.get_current_state()\n",
    "print(tello_state)\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"----------- New State Record -------\")\n",
    "    tello_state = tello.get_current_state()\n",
    "    pprint(tello_state, indent=2)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()  # 착륙\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2) Motion control\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.1) UP&DOWN\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/02_move_up_down.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 02_move_up_down.py\n",
    "from djitellopy import Tello\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()\n",
    "\n",
    "print(\"Move Up\")\n",
    "tello.move_up(40)\n",
    "\n",
    "print(\"Move Down\")\n",
    "tello.move_down(40)\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.2) LEFT&RIGHT\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/03_move_left_right.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 03_move_left_right.py\n",
    "from djitellopy import Tello\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()\n",
    "\n",
    "print(\"Move Left\")\n",
    "tello.move_left(40)\n",
    "\n",
    "print(\"Move Right\")\n",
    "tello.move_right(40)\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.3) Forward&Backward\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/04_move_forward_backwards.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 04_move_forward_backwards.py\n",
    "from djitellopy import Tello\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()\n",
    "\n",
    "print(\"Move Forward\")\n",
    "tello.move_forward(40)\n",
    "\n",
    "print(\"Move Backwards\")\n",
    "tello.move_back(40)\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.4) Rotate CW&CCW\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/05_rotate_cw_ccw.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 05_rotate_cw_ccw.py\n",
    "from djitellopy import Tello\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()\n",
    "\n",
    "print(\"Rotate Clockwise\")\n",
    "tello.rotate_clockwise(90)\n",
    "\n",
    "print(\"Rotate Counter Clockwise\")\n",
    "tello.rotate_counter_clockwise(90)\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.5) Flip Left&Right\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/06_flip_left_right.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 06_flip_left_right.py\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"Flip left\")\n",
    "tello.flip_left()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"Flip Right\")\n",
    "tello.flip_right()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"Flip Forward\")\n",
    "tello.flip_forward()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"Flip Backward\")\n",
    "tello.flip_back()\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.6) Move by XYZ position\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/07_go_xyz.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 07_go_xyz.py\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()\n",
    "\n",
    "# tello.go_xyz_speed(x,y,z, speed)\n",
    "# x - (+)foward/(-)backwards\n",
    "# y - (+)left/(-)right\n",
    "# z - (+)up/(-)down\n",
    "\n",
    "# Forward, Right, Up\n",
    "print(\"Go x,y,z: (30,-30,30)\")\n",
    "tello.go_xyz_speed(30,-30,30, 20)\n",
    "\n",
    "# Note that the DJITelloPy documentation indicates that the values\n",
    "# x,y,z are between 20-500, the official documentation states the\n",
    "# valid values are from -500-500\n",
    "# Backwards, Left, Down\n",
    "print(\"Go x,y,z: (-60,60,-60)\")\n",
    "tello.go_xyz_speed(-60,60,-60, 20)\n",
    "\n",
    "# Forward, Right, Up\n",
    "print(\"Go x,y,z: (30,-30,30)\")\n",
    "tello.go_xyz_speed(30,-30,30, 20)\n",
    "\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.7) Move by XYZ posizion to criss cross\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/08_criss_cross.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 08_criss_cross.py\n",
    "from djitellopy import Tello\n",
    "import time\n",
    "\n",
    "try:\n",
    "    tello.end()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "tello.takeoff()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "\"\"\"\n",
    "Flight Patter\n",
    "    2     4\n",
    "    |\\   /|\n",
    "    | \\ / |\n",
    "    |  \\  |\n",
    "    | / \\ |\n",
    "   1 5   3\n",
    "\"\"\"\n",
    "\n",
    "travel_distance_cm = 50\n",
    "#tello.go_xyz_speed(x,y,z, speed)\n",
    "\n",
    "# x - (+)foward/(-)backwards\n",
    "# y - (+)left/(-)right\n",
    "# z - (+)up/(-)down\n",
    "tello.go_xyz_speed(0, 0, travel_distance_cm, 20)\n",
    "print(\"sleep\")\n",
    "time.sleep(0.5)\n",
    "tello.go_xyz_speed(0, travel_distance_cm, -travel_distance_cm, 20)\n",
    "print(\"sleep\")\n",
    "time.sleep(0.5)\n",
    "tello.go_xyz_speed(0, 0, travel_distance_cm, 20)\n",
    "print(\"sleep\")\n",
    "time.sleep(0.5)\n",
    "\n",
    "# x - (+)foward/(-)backwards\n",
    "# y - (+)left/(-)right\n",
    "# z - (+)up/(-)down\n",
    "tello.go_xyz_speed(0, -travel_distance_cm, -travel_distance_cm, 20)\n",
    "print(\"sleep\")\n",
    "time.sleep(0.5)\n",
    "\n",
    "print(\"landing\")\n",
    "tello.land()\n",
    "print(\"touchdown.... goodbye\")\n",
    "time.sleep(3)\n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3) Camera test\n",
    "-[ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/10_take_picture.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.1) Take a picture\n",
    "\n",
    "- [ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/00_test_installation.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 3.1) Take a picture\n",
    "from djitellopy import Tello\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"Turn Video Stream On\")\n",
    "tello.streamon()\n",
    "\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "print(\"Takeoff!\")\n",
    "# tello.takeoff()\n",
    "\n",
    "print(\"I will take a picture in 2 seconds\")\n",
    "time.sleep(1)\n",
    "print(\"I will take a picture in 1 seconds\")\n",
    "time.sleep(1)\n",
    "\n",
    "# read a single image from the Tello video feed\n",
    "print(\"Read Tello Image\")\n",
    "tello_video_image = frame_read.frame\n",
    "\n",
    "print(\"Write tello-picture.png\")\n",
    "# use opencv to write image\n",
    "cv2.imwrite(\"tello-picture.png\", tello_video_image)  # BGR, RGB가 아님. 변환필요\n",
    "\n",
    "print(\"Land\")\n",
    "# tello.land()\n",
    "\n",
    "print(\"Turn Tello video stream off\")\n",
    "tello.streamoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.2) Take a video_feed_no_flying\n",
    "- [ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/11_video_feed_no_flying.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 3.1) Take a video_feed_no_flying\n",
    "from djitellopy import Tello\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"Turn Video Stream On\")\n",
    "tello.streamon()\n",
    "\n",
    "# read a single image from the Tello video feed\n",
    "print(\"Read Tello Image\")\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "time.sleep(2)\n",
    "while True:\n",
    "    # read a single image from the Tello video feed\n",
    "    print(\"Read Tello Image\")\n",
    "    tello_video_image = frame_read.frame\n",
    "\n",
    "    # use opencv to write image\n",
    "    if tello_video_image is not None:\n",
    "        cv2.imshow(\"TelloVideo\", tello_video_image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "tello.streamoff()\n",
    "cv2.destroyWindow('TelloVideo')\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.3) Take a video_feed_while_flying\n",
    "- [ref](https://github.com/dbaldwin/DroneBlocks-DJITelloPy-Tutorial/blob/master/13_video_feed_flying_synchronous.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     12
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 3.3) Take a video_feed_while_flying\n",
    "from djitellopy import Tello\n",
    "import cv2\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "speed = 25\n",
    "command_time_seconds = 3\n",
    "\n",
    "landing_flag = False\n",
    "\n",
    "\n",
    "def flight_pattern():\n",
    "    print(\"Takeoff!\")\n",
    "    tello.takeoff()\n",
    "\n",
    "    if not tello.is_flying:\n",
    "        # something happened... lets try one more time\n",
    "        tello.takeoff()\n",
    "\n",
    "    tello.move_up(20)\n",
    "\n",
    "    time.sleep(1)\n",
    "    up_flag = True\n",
    "    start_time = time.time()\n",
    "    t1 = time.time()\n",
    "\n",
    "    while True:\n",
    "        if time.time() - start_time > 10\n",
    "            landing_flag = True\n",
    "        \n",
    "        if landing_flag:\n",
    "            # if the landing_flag is set to try then break\n",
    "            # out of the 'while' loop and exit the function\n",
    "            break\n",
    "\n",
    "        if time.time() - t1 > 3:\n",
    "            t1 = time.time()\n",
    "            if up_flag == True:\n",
    "                up_flag = False\n",
    "                # Up\n",
    "                tello.move_up(30)\n",
    "            else:\n",
    "                up_flag = True\n",
    "                tello.move_down(30)\n",
    "\n",
    "\n",
    "print(\"Create Tello object\")\n",
    "tello = Tello()\n",
    "\n",
    "print(\"Connect to Tello Drone\")\n",
    "tello.connect()\n",
    "\n",
    "battery_level = tello.get_battery()\n",
    "print(f\"Battery Life Percentage: {battery_level}\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"Turn Video Stream On\")\n",
    "tello.streamon()\n",
    "\n",
    "# read a single image from the Tello video feed\n",
    "print(\"Read Tello Image\")\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "# create a thread to run the function\n",
    "flight_pattern_thread = Thread(target=flight_pattern, daemon=True)\n",
    "flight_pattern_thread.start()\n",
    "\n",
    "time.sleep(2)\n",
    "print('Press:  q  to quit')\n",
    "while True:\n",
    "    # read a single image from the Tello video feed\n",
    "    tello_video_image = frame_read.frame\n",
    "\n",
    "    # use opencv to write image\n",
    "    if tello_video_image is not None:\n",
    "        cv2.imshow(\"TelloVideo\", tello_video_image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# set a flag to instruct flight_pattern function to exit\n",
    "landing_flag = True\n",
    "\n",
    "tello.land()\n",
    "time.sleep(1)\n",
    "\n",
    "tello.streamoff()\n",
    "cv2.destroyWindow('TelloVideo')\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.4) Record a video_feed_while_flying (error있음. 저장된 영상이 재생안됨)\n",
    "- [ref](https://github.com/damiafuentes/DJITelloPy/blob/master/examples/record-video.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 3.4) Record a video_feed_while_flying\n",
    "import time, cv2\n",
    "from threading import Thread\n",
    "from djitellopy import Tello\n",
    "\n",
    "tello = Tello()\n",
    "\n",
    "tello.connect()\n",
    "\n",
    "keepRecording = True\n",
    "tello.streamon()\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "def videoRecorder():\n",
    "    # create a VideoWrite object, recoring to ./video.avi\n",
    "    height, width, _ = frame_read.frame.shape\n",
    "    video = cv2.VideoWriter('./TT_video.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 30, (width, height))\n",
    "\n",
    "    while keepRecording:\n",
    "        video.write(frame_read.frame)\n",
    "        time.sleep(1 / 30)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "# we need to run the recorder in a seperate thread, otherwise blocking options\n",
    "#  would prevent frames from getting added to the video\n",
    "recorder = Thread(target=videoRecorder)\n",
    "recorder.start()\n",
    "\n",
    "# tello.takeoff()\n",
    "# tello.move_up(100)\n",
    "# tello.rotate_counter_clockwise(360)\n",
    "# tello.land()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "keepRecording = False\n",
    "recorder.join()\n",
    "print('save video done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.5) Take a panorama picture\n",
    "- [ref1](https://github.com/damiafuentes/DJITelloPy/blob/master/examples/panorama/panorama.py)\n",
    "- [ref2](https://github.com/damiafuentes/DJITelloPy/blob/master/examples/panorama/panoramaModule.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10,
     29,
     50,
     69
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 3.5) Take a panorama picture\n",
    "\n",
    "## panoramaModule.py functions\n",
    "from djitellopy import Tello\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "global img\n",
    "\n",
    "class panoramaModule_class:\n",
    "    def panorama_full_clockwise(self, tello_name):\n",
    "        tello = tello_name\n",
    "        tello.streamoff()\n",
    "        tello.streamon()\n",
    "\n",
    "        for i in range(4):\n",
    "            img = tello.get_frame_read().frame\n",
    "            cv2.imwrite(f'Panorama-full-clockwise_{time.time()}.jpg', img)\n",
    "            time.sleep(1)\n",
    "            tello.rotate_clockwise(80)\n",
    "\n",
    "        img = tello.get_frame_read().frame\n",
    "        cv2.imwrite(f'Panorama-full-clockwise_{time.time()}.jpg', img)\n",
    "        time.sleep(1)\n",
    "        tello.rotate_clockwise(40)\n",
    "\n",
    "        tello.streamoff()\n",
    "\n",
    "\n",
    "    def panorama_half_clockwise(self, tello_name):\n",
    "        tello = tello_name\n",
    "        tello.streamoff()\n",
    "        tello.streamon()\n",
    "\n",
    "        tello.rotate_counter_clockwise(90)\n",
    "\n",
    "        for i in range(3):\n",
    "            img = tello.get_frame_read().frame\n",
    "            cv2.imwrite(f'Panorama-half-clockwise_{time.time()}.jpg', img)\n",
    "            time.sleep(1)\n",
    "            tello.rotate_clockwise(60)\n",
    "\n",
    "        img = tello.get_frame_read().frame\n",
    "        cv2.imwrite(f'Panorama-half-clockwise_{time.time()}.jpg', img)\n",
    "        time.sleep(1)\n",
    "        tello.rotate_counter_clockwise(90)\n",
    "\n",
    "        tello.streamoff()\n",
    "\n",
    "\n",
    "    def panorama_full_counter_clockwise(self, tello_name):\n",
    "        tello = tello_name\n",
    "        tello.streamoff()\n",
    "        tello.streamon()\n",
    "\n",
    "        for i in range(4):\n",
    "            img = tello.get_frame_read().frame\n",
    "            cv2.imwrite(f'Panorama-full-counter-clockwise_{time.time()}.jpg', img)\n",
    "            time.sleep(1)\n",
    "            tello.rotate_counter_clockwise(80)\n",
    "\n",
    "        img = tello.get_frame_read().frame\n",
    "        cv2.imwrite(f'/Panorama-full-counter-clockwise_{time.time()}.jpg', img)\n",
    "        time.sleep(1)\n",
    "        tello.rotate_counter_clockwise(40)\n",
    "\n",
    "        tello.streamoff()\n",
    "\n",
    "\n",
    "    def panorama_half_counter_clockwise(self, tello_name):\n",
    "        tello = tello_name\n",
    "        tello.streamoff()\n",
    "        tello.streamon()\n",
    "\n",
    "        tello.rotate_clockwise(90)\n",
    "\n",
    "        for i in range(3):\n",
    "            img = tello.get_frame_read().frame\n",
    "            cv2.imwrite(f'Panorama-half-counter-clockwise_{time.time()}.jpg', img)\n",
    "            time.sleep(1)\n",
    "            tello.rotate_counter_clockwise(60)\n",
    "\n",
    "        img = tello.get_frame_read().frame\n",
    "        cv2.imwrite(f'Panorama_half_counter_clockwise-{time.time()}.jpg', img)\n",
    "        time.sleep(1)\n",
    "        tello.rotate_clockwise(90)\n",
    "\n",
    "        tello.streamoff()\n",
    "        \n",
    "panoramaModule = panoramaModule_class()\n",
    "\n",
    "\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "print(tello.get_battery())\n",
    "\n",
    "tello.takeoff()\n",
    "tello.move_up(40)\n",
    "panoramaModule.panorama_half_clockwise(tello)\n",
    "tello.land()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4) Controll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 4.1) manual-control-opencv.\n",
    "- [ref](https://github.com/damiafuentes/DJITelloPy/blob/master/examples/manual-control-opencv.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 4.1) manual-control-opencv.py\n",
    "from djitellopy import Tello\n",
    "import cv2, math, time\n",
    "\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "tello.streamon()\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "tello.takeoff()\n",
    "\n",
    "while True:\n",
    "    # In reality you want to display frames in a seperate thread\n",
    "    # Otherwise they will freeze while the drone moves.\n",
    "    img = frame_read.frame\n",
    "    cv2.imshow(\"drone\", img)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xff\n",
    "    if key == 50: # ESC\n",
    "        break\n",
    "    elif key == ord('w'):\n",
    "        tello.move_forward(30)\n",
    "    elif key == ord('s'):\n",
    "        tello.move_back(30)\n",
    "    elif key == ord('a'):\n",
    "        tello.move_left(30)\n",
    "    elif key == ord('d'):\n",
    "        tello.move_right(30)\n",
    "    elif key == ord('e'):\n",
    "        tello.rotate_clockwise(30)\n",
    "    elif key == ord('q'):\n",
    "        tello.rotate_counter_clockwise(30)\n",
    "    elif key == ord('r'):\n",
    "        tello.move_up(30)\n",
    "    elif key == ord('f'):\n",
    "        tello.move_down(30)\n",
    "    elif key == ord('c'):\n",
    "        tello.land()\n",
    "\n",
    "tello.land()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4.2) manual-control-pygame\n",
    "- [ref](https://github.com/damiafuentes/DJITelloPy/blob/master/examples/manual-control-pygame.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 4.2) manual-control-pygame.py\n",
    "from djitellopy import Tello\n",
    "import cv2\n",
    "import pygame\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Speed of the drone\n",
    "S = 60\n",
    "# Frames per second of the pygame window display\n",
    "# A low number also results in input lag, as input information is processed once per frame.\n",
    "FPS = 120\n",
    "\n",
    "\n",
    "class FrontEnd(object):\n",
    "    \"\"\" Maintains the Tello display and moves it through the keyboard keys.\n",
    "        Press escape key to quit.\n",
    "        The controls are:\n",
    "            - T: Takeoff\n",
    "            - L: Land\n",
    "            - Arrow keys: Forward, backward, left and right.\n",
    "            - A and D: Counter clockwise and clockwise rotations (yaw)\n",
    "            - W and S: Up and down.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Init pygame\n",
    "        pygame.init()\n",
    "\n",
    "        # Creat pygame window\n",
    "        pygame.display.set_caption(\"Tello video stream\")\n",
    "        self.screen = pygame.display.set_mode([960, 720])\n",
    "\n",
    "        # Init Tello object that interacts with the Tello drone\n",
    "        self.tello = Tello()\n",
    "\n",
    "        # Drone velocities between -100~100\n",
    "        self.for_back_velocity = 0\n",
    "        self.left_right_velocity = 0\n",
    "        self.up_down_velocity = 0\n",
    "        self.yaw_velocity = 0\n",
    "        self.speed = 10\n",
    "\n",
    "        self.send_rc_control = False\n",
    "\n",
    "        # create update timer\n",
    "        pygame.time.set_timer(pygame.USEREVENT + 1, 1000 // FPS)\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        self.tello.connect()\n",
    "        self.tello.set_speed(self.speed)\n",
    "\n",
    "        # In case streaming is on. This happens when we quit this program without the escape key.\n",
    "        self.tello.streamoff()\n",
    "        self.tello.streamon()\n",
    "\n",
    "        frame_read = self.tello.get_frame_read()\n",
    "\n",
    "        should_stop = False\n",
    "        while not should_stop:\n",
    "\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.USEREVENT + 1:\n",
    "                    self.update()\n",
    "                elif event.type == pygame.QUIT:\n",
    "                    should_stop = True\n",
    "                elif event.type == pygame.KEYDOWN:\n",
    "                    if event.key == pygame.K_ESCAPE:\n",
    "                        should_stop = True\n",
    "                    else:\n",
    "                        self.keydown(event.key)\n",
    "                elif event.type == pygame.KEYUP:\n",
    "                    self.keyup(event.key)\n",
    "\n",
    "            if frame_read.stopped:\n",
    "                break\n",
    "\n",
    "            self.screen.fill([0, 0, 0])\n",
    "\n",
    "            frame = frame_read.frame\n",
    "            # battery n.\n",
    "            text = \"Battery: {}%\".format(self.tello.get_battery())\n",
    "            cv2.putText(frame, text, (5, 720 - 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = np.rot90(frame)\n",
    "            frame = np.flipud(frame)\n",
    "\n",
    "            frame = pygame.surfarray.make_surface(frame)\n",
    "            self.screen.blit(frame, (0, 0))\n",
    "            pygame.display.update()\n",
    "\n",
    "            time.sleep(1 / FPS)\n",
    "\n",
    "        # Call it always before finishing. To deallocate resources.\n",
    "        self.tello.end()\n",
    "\n",
    "    def keydown(self, key):\n",
    "        if key == pygame.K_UP:  # set forward velocity\n",
    "            self.for_back_velocity = S\n",
    "        elif key == pygame.K_DOWN:  # set backward velocity\n",
    "            self.for_back_velocity = -S\n",
    "        elif key == pygame.K_LEFT:  # set left velocity\n",
    "            self.left_right_velocity = -S\n",
    "        elif key == pygame.K_RIGHT:  # set right velocity\n",
    "            self.left_right_velocity = S\n",
    "        elif key == pygame.K_w:  # set up velocity\n",
    "            self.up_down_velocity = S\n",
    "        elif key == pygame.K_s:  # set down velocity\n",
    "            self.up_down_velocity = -S\n",
    "        elif key == pygame.K_a:  # set yaw counter clockwise velocity\n",
    "            self.yaw_velocity = -S\n",
    "        elif key == pygame.K_d:  # set yaw clockwise velocity\n",
    "            self.yaw_velocity = S\n",
    "\n",
    "    def keyup(self, key):\n",
    "        if key == pygame.K_UP or key == pygame.K_DOWN:  # set zero forward/backward velocity\n",
    "            self.for_back_velocity = 0\n",
    "        elif key == pygame.K_LEFT or key == pygame.K_RIGHT:  # set zero left/right velocity\n",
    "            self.left_right_velocity = 0\n",
    "        elif key == pygame.K_w or key == pygame.K_s:  # set zero up/down velocity\n",
    "            self.up_down_velocity = 0\n",
    "        elif key == pygame.K_a or key == pygame.K_d:  # set zero yaw velocity\n",
    "            self.yaw_velocity = 0\n",
    "        elif key == pygame.K_t:  # takeoff\n",
    "            self.tello.takeoff()\n",
    "            self.send_rc_control = True\n",
    "        elif key == pygame.K_l:  # land\n",
    "            not self.tello.land()\n",
    "            self.send_rc_control = False\n",
    "\n",
    "    def update(self):\n",
    "        if self.send_rc_control:\n",
    "            self.tello.send_rc_control(self.left_right_velocity, self.for_back_velocity,\n",
    "                self.up_down_velocity, self.yaw_velocity)\n",
    "\n",
    "\n",
    "def main():\n",
    "    frontend = FrontEnd()\n",
    "\n",
    "    # run frontend\n",
    "    frontend.run()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5)  군집비행\n",
    "-[ref](https://github.com/damiafuentes/DJITelloPy/blob/master/examples/simple-swarm.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 5) 군집비행\n",
    "from djitellopy import TelloSwarm\n",
    "\n",
    "# TT의 각 ip 입력\n",
    "swarm = TelloSwarm.fromIps([\n",
    "    \"192.168.178.42\",\n",
    "    \"192.168.178.43\",\n",
    "    \"192.168.178.44\"\n",
    "])\n",
    "\n",
    "swarm.connect()\n",
    "swarm.takeoff()\n",
    "\n",
    "# run in parallel on all tellos\n",
    "swarm.move_up(100)\n",
    "\n",
    "# run by one tello after the other\n",
    "swarm.sequential(lambda i, tello: tello.move_forward(i * 20 + 20))\n",
    "\n",
    "# making each tello do something unique in parallel\n",
    "swarm.parallel(lambda i, tello: tello.move_left(i * 100 + 20))\n",
    "\n",
    "swarm.land()\n",
    "swarm.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) 인공지능 기반 드론 제어\n",
    "- [ref1](https://github.com/murtazahassan/Tello-Object-Tracking)\n",
    "- [ref2](https://youtu.be/vDOkUHNdmKs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 6.1) 음성기반 드론제어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.1.1) 음성 인식/합성 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# install\n",
    "## 1) 음성합성 (TTS, Text-to-Speech)\n",
    "!pip install pyttsx3==2.90\n",
    "!pip install gtts==2.2.4\n",
    "!pip install playsound==1.3.0\n",
    "!pip install langdetect==1.0.9\n",
    "\n",
    "## 2) 음성인식 (Speech-to-Text)\n",
    "!pip install PyAudio==0.2.12\n",
    "!pip install SpeechRecognition==3.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 체크 1) 음성합성(TTS) 1\n",
    "import pyttsx3\n",
    "def 스피커(text='자비스 안녕? 준비됐어?', 목소리선택=0):\n",
    "\n",
    "    engine = pyttsx3.init()\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[목소리선택].id)\n",
    "\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    return\n",
    "\n",
    "스피커(text='자비스 안녕? 준비됐어?', 목소리선택=0)\n",
    "스피커(text='Hello Jarvis?? Are you ready??', 목소리선택=1)\n",
    "스피커(text='Hello Jarvis?? Are you ready??', 목소리선택=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## 체크2 ) 음성합성(TTS) 2\n",
    "# # TTS 구글꺼. 성능 이상함\n",
    "# # !pip install gtts\n",
    "# # !pip install playsound==1.3.0\n",
    "# # !pip install langdetect\n",
    "\n",
    "# from gtts import gTTS\n",
    "# from playsound import playsound\n",
    "# import os\n",
    "# import time\n",
    "# from IPython.display import Audio\n",
    "# from langdetect import detect\n",
    "\n",
    "\n",
    "# def 스피커(text='AI비서 만들기 프로젝트에 오신것을 환영합니다'):\n",
    "\n",
    "#     text = str(text)\n",
    "#     file_path = './sample.mp3'\n",
    "#     if os.path.isfile(file_path):\n",
    "#         os.remove(file_path)\n",
    "\n",
    "#     # 언어 감지, 영어? 한국어?\n",
    "#     try:\n",
    "#         language = detect(text)\n",
    "#         if language == 'ko':\n",
    "#             language = 'ko'\n",
    "#         else:\n",
    "#             language = 'en'\n",
    "#     except:\n",
    "#         language = 'ko'\n",
    "\n",
    "#     print(f'언어: {language}')\n",
    "#     tts_en = gTTS(text=text, lang=language)\n",
    "#     if os.path.isfile(file_path):\n",
    "#         os.remove(file_path)\n",
    "#     tts_en.save(file_path)\n",
    "#     wn = Audio(file_path, autoplay=True)\n",
    "#     display(wn)\n",
    "#     time.sleep(3)\n",
    "\n",
    "\n",
    "# 스피커(text='Are you hungry??')\n",
    "# 스피커(text='AI비서 만들기 프로젝트에 오신것을 환영합니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 체크3 ) 음성인식(STT)\n",
    "# 음성인식 체크\n",
    "import speech_recognition as sr\n",
    "print(f'사용 가능 마이크\\n => {sr.Microphone.list_microphone_names()}')\n",
    "r = sr.Recognizer()\n",
    "\n",
    "def 음성인식(r, 언어='한국어'):\n",
    "    \n",
    "    with sr.Microphone() as source:\n",
    "        print('#'*50)\n",
    "        print('Listening..')\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source)\n",
    "\n",
    "        try:\n",
    "            print('Recognizing..')\n",
    "            if 언어=='한국어':\n",
    "                query = r.recognize_google(audio, language='ko-KR')  # https://cloud.google.com/speech-to-text/docs/languages\n",
    "            else:\n",
    "                query = r.recognize_google(audio, language='en-US')\n",
    "            print(query)\n",
    "            스피커(text=query)\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            스피커(text='다시 말씀해 주시겠어요?')\n",
    "            return 'None'\n",
    "\n",
    "        return query\n",
    "    \n",
    "음성인식결과 = 음성인식(r, 언어='한국어')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.1.2) 음성 인식/합성 제어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 6.2) 음성 인식/합성 제어\n",
    "\n",
    "\n",
    "## 음성제어 시나리오\n",
    "# 1) 이륙\n",
    "# 2) 위로\n",
    "# 3) 왼쪽\n",
    "# 4) 돌아\n",
    "# 5) 뒤집어\n",
    "# 6) 파노라마\n",
    "# 7) 십자가\n",
    "# 8) 착륙\n",
    "\n",
    "from djitellopy import Tello\n",
    "import cv2, math, time\n",
    "\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "tello.streamon()\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "\n",
    "\n",
    "거리 = 30\n",
    "cnt = 0\n",
    "print('명령을 내려주세요')\n",
    "스피커(text='명령을 내려주세요~~', 목소리선택=0)\n",
    "while True:\n",
    "    음성인식결과 = 음성인식(r, 언어='한국어')\n",
    "\n",
    "    if \"이륙\" in 음성인식결과:\n",
    "        print(\"이륙\")\n",
    "        스피커(text='이륙')\n",
    "        tello.takeoff()\n",
    "        cnt += 1\n",
    "\n",
    "    elif \"위로\" in 음성인식결과:\n",
    "        print(\"Move Up\")\n",
    "        스피커(text='Move Up')\n",
    "        tello.takeoff()        \n",
    "        tello.move_up(거리)\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "\n",
    "    elif \"아래로\" in 음성인식결과:\n",
    "        print(\"Move Down\")\n",
    "        스피커(text='Move Down')\n",
    "        tello.takeoff()        \n",
    "        tello.move_down(거리)\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "\n",
    "    elif \"왼쪽\" in 음성인식결과:\n",
    "        print(\"Move Left\")\n",
    "        스피커(text='Move Left')\n",
    "        tello.takeoff()        \n",
    "        tello.move_left(거리)\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "\n",
    "    elif \"오른쪽\" in 음성인식결과:\n",
    "        print(\"Move Right\")\n",
    "        스피커(text='Move Right')\n",
    "        tello.takeoff()        \n",
    "        tello.move_right(거리)\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "\n",
    "    elif \"앞으로\" in 음성인식결과:\n",
    "        print(\"Move Forward\")\n",
    "        스피커(text='Move Forward')\n",
    "        tello.takeoff()        \n",
    "        tello.move_forward(거리)\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "\n",
    "    elif \"뒤로\" in 음성인식결과:\n",
    "        print(\"Move Down\")\n",
    "        스피커(text='Move Down')\n",
    "        tello.takeoff()        \n",
    "        tello.move_back(거리)\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "\n",
    "    elif \"돌아\" in 음성인식결과:\n",
    "        print(\"Rotate Clockwise\")\n",
    "        스피커(text='Move Down')  \n",
    "        tello.takeoff()        \n",
    "        tello.rotate_clockwise(90)\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "\n",
    "    elif \"뒤집어\" in 음성인식결과:\n",
    "        print(\"Flip left\")\n",
    "        스피커(text='Move Down')\n",
    "        tello.takeoff()        \n",
    "        tello.flip_left()\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "\n",
    "    elif \"십자가\" in 음성인식결과:\n",
    "        print('십자가')\n",
    "        스피커(text='십자가')\n",
    "        tello.takeoff()\n",
    "        travel_distance_cm = 50\n",
    "        #tello.go_xyz_speed(x,y,z, speed)\n",
    "\n",
    "        # x - (+)foward/(-)backwards\n",
    "        # y - (+)left/(-)right\n",
    "        # z - (+)up/(-)down\n",
    "        tello.go_xyz_speed(0, 0, travel_distance_cm, 20)\n",
    "        time.sleep(0.5)\n",
    "        tello.go_xyz_speed(0, travel_distance_cm, -travel_distance_cm, 20)\n",
    "        time.sleep(0.5)\n",
    "        tello.go_xyz_speed(0, 0, travel_distance_cm, 20)\n",
    "        time.sleep(0.5)\n",
    "        # x - (+)foward/(-)backwards\n",
    "        # y - (+)left/(-)right\n",
    "        # z - (+)up/(-)down\n",
    "        tello.go_xyz_speed(0, -travel_distance_cm, -travel_distance_cm, 20)\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    elif \"사진\" in 음성인식결과:\n",
    "        print('사진을 저장합니다')\n",
    "        스피커(text='사진을 저장합니다')\n",
    "        tello.takeoff()\n",
    "        tello_video_image = frame_read.frame\n",
    "        cv2.imwrite(\"tello-picture.png\", tello_video_image)  # BGR, RGB가 아님. 변환필요\n",
    "        time.sleep(0.5)\n",
    "        tello.land()        \n",
    "        cnt += 1\n",
    "        \n",
    "    elif \"파노라마\" in 음성인식결과:\n",
    "        print('파노라마')\n",
    "        스피커(text='파노라마')\n",
    "        tello.takeoff()        \n",
    "        tello.move_up(거리)\n",
    "        panoramaModule.panorama_half_clockwise(tello)\n",
    "        time.sleep(0.5)\n",
    "        tello.land()\n",
    "        cnt += 1\n",
    "        \n",
    "    # 8번 동작했으면 착륙\n",
    "    elif (\"착륙\" in 음성인식결과) or cnt > 8:\n",
    "        print('착륙')\n",
    "        스피커(text='landing')\n",
    "        print(\"landing\")\n",
    "        tello.land()\n",
    "        time.sleep(0.5)        \n",
    "        cnt += 1\n",
    "    else:\n",
    "        print('다시 한번 말씀해 주시겠어요?')\n",
    "        \n",
    "tello.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 6.2) human pose 기반 드론 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.2.1) mediapipe 준비\n",
    "\n",
    "- [ref](https://google.github.io/mediapipe/solutions/pose)\n",
    "![](https://mediapipe.dev/images/mobile/pose_tracking_example.gif)\n",
    "![](https://mediapipe.dev/images/mobile/pose_tracking_full_body_landmarks.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## install mediapipe\n",
    "!pip install mediapipe==0.9.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load mediapipe\n",
    "import mediapipe as mp\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "help(mp_pose.Pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check input image\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 이미지 크기 설정\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "# 이미지 resize 함수\n",
    "def resize_and_show(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image,\n",
    "                         (DESIRED_WIDTH, math.floor(h / (w / DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(\n",
    "            image, (math.floor(w / (h / DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "#     cv2.imshow('image', img)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('image')\n",
    "    plt.show()\n",
    "\n",
    "list_image_path = glob(os.path.join('example', 'test*.jpg'))  # ['./test1.jpg', './test2.jpg', ..]\n",
    "# list_image_path = ['./test1.jpg', './test2.jpg']\n",
    "\n",
    "# Read images with OpenCV.\n",
    "images = {name: cv2.imread(name) for name in list_image_path}\n",
    "# Preview the images.\n",
    "for name, image in images.items():\n",
    "    print(name)\n",
    "    resize_and_show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run MediaPipe Pose and draw pose landmarks.\n",
    "with mp_pose.Pose(static_image_mode=True,\n",
    "                  min_detection_confidence=0.5,\n",
    "                  model_complexity=2) as pose:\n",
    "    for name, image in images.items():\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print nose landmark.\n",
    "        image_hight, image_width, _ = image.shape\n",
    "        if not results.pose_landmarks:\n",
    "            continue\n",
    "        print(\n",
    "            f'Nose coordinates: ('\n",
    "            f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width}, '\n",
    "            f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_hight})'\n",
    "        )\n",
    "\n",
    "        # Draw pose landmarks.\n",
    "        print(f'Pose landmarks of {name}:')\n",
    "        annotated_image = image.copy()\n",
    "        mp_drawing.draw_landmarks(annotated_image,\n",
    "                                  results.pose_landmarks,\n",
    "                                  mp_pose.POSE_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=mp_drawing_styles.\n",
    "                                  get_default_pose_landmarks_style())\n",
    "        resize_and_show(annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run MediaPipe Pose and plot 3d pose world landmarks.\n",
    "with mp_pose.Pose(static_image_mode=True,\n",
    "                  min_detection_confidence=0.5,\n",
    "                  model_complexity=2) as pose:\n",
    "    for name, image in images.items():\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print the real-world 3D coordinates of nose in meters with the origin at\n",
    "        # the center between hips.\n",
    "        print('Nose world landmark:'),\n",
    "        print(results.pose_world_landmarks.landmark[mp_pose.PoseLandmark.NOSE])\n",
    "\n",
    "        # Plot pose world landmarks.\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks,\n",
    "                                  mp_pose.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.2.2) mediapipe pose estimation with webcam\n",
    "- [ref](https://google.github.io/mediapipe/solutions/pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mediapipe pose estimation with webcam\n",
    "# select camera type\n",
    "camera_type = 'notebook'\n",
    "# camera_type = 'webcam'\n",
    "\n",
    "if camera_type == 'notebook':\n",
    "    camera_idx = 0\n",
    "elif camera_type == 'webcam':\n",
    "    camera_idx = 1\n",
    "else:\n",
    "    assert 'select camera type'\n",
    "\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(camera_idx)\n",
    "if not cap.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    print('open webcam & run pose')\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Draw the pose annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(image,\n",
    "                                  results.pose_landmarks,\n",
    "                                  mp_pose.POSE_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=mp_drawing_styles.\n",
    "                                  get_default_pose_landmarks_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Pose', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.2.3) pose estimation 기반 드론 제어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     109,
     210
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## mp-skeleton util functions\n",
    "def make_mediapipe_result2position(image, results, verbose=False):\n",
    "    position={}\n",
    "    ## NOSE\n",
    "    idx_landmark = mp_pose.PoseLandmark.NOSE\n",
    "    position['NOSE']={}\n",
    "    position['NOSE']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['NOSE']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['NOSE']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    ## NOSE\n",
    "    idx_landmark = mp_pose.PoseLandmark.NOSE\n",
    "    position['NOSE']={}\n",
    "    position['NOSE']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['NOSE']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['NOSE']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    ## LEFT_SHOULDER\n",
    "    idx_landmark = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "    position['LEFT_SHOULDER']={}\n",
    "    position['LEFT_SHOULDER']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['LEFT_SHOULDER']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['LEFT_SHOULDER']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    ## LEFT_HIP\n",
    "    idx_landmark = mp_pose.PoseLandmark.LEFT_HIP\n",
    "    position['LEFT_HIP']={}\n",
    "    position['LEFT_HIP']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['LEFT_HIP']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['LEFT_HIP']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    ## LEFT_ELBOW\n",
    "    idx_landmark = mp_pose.PoseLandmark.LEFT_ELBOW\n",
    "    position['LEFT_ELBOW']={}\n",
    "    position['LEFT_ELBOW']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['LEFT_ELBOW']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['LEFT_ELBOW']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    ## LEFT_ELBOW\n",
    "    idx_landmark = mp_pose.PoseLandmark.LEFT_WRIST\n",
    "    position['LEFT_WRIST']={}\n",
    "    position['LEFT_WRIST']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['LEFT_WRIST']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['LEFT_WRIST']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    \n",
    "    ## RIGHT_SHOULDER\n",
    "    idx_landmark = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "    position['RIGHT_SHOULDER']={}\n",
    "    position['RIGHT_SHOULDER']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['RIGHT_SHOULDER']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['RIGHT_SHOULDER']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    ## RIGHT_HIP\n",
    "    idx_landmark = mp_pose.PoseLandmark.RIGHT_HIP\n",
    "    position['RIGHT_HIP']={}\n",
    "    position['RIGHT_HIP']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['RIGHT_HIP']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['RIGHT_HIP']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    ## RIGHT_ELBOW\n",
    "    idx_landmark = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "    position['RIGHT_ELBOW']={}\n",
    "    position['RIGHT_ELBOW']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['RIGHT_ELBOW']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['RIGHT_ELBOW']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    ## RIGHT_WRIST\n",
    "    idx_landmark = mp_pose.PoseLandmark.RIGHT_WRIST\n",
    "    position['RIGHT_WRIST']={}\n",
    "    position['RIGHT_WRIST']['x']=int(results.pose_landmarks.landmark[idx_landmark].x * image_width)\n",
    "    position['RIGHT_WRIST']['y']=int(results.pose_landmarks.landmark[idx_landmark].y * image_hight)\n",
    "    position['RIGHT_WRIST']['score']=results.pose_landmarks.landmark[idx_landmark].visibility\n",
    "    \n",
    "    image = cv2.circle(image, (position['NOSE']['x'], position['NOSE']['y']), 1, (255,0,0), 10)  # red\n",
    "    image = cv2.circle(image, (position['LEFT_SHOULDER']['x'], position['LEFT_SHOULDER']['y']), 1, (255,255,0), 10)  # yello\n",
    "    image = cv2.circle(image, (position['RIGHT_SHOULDER']['x'], position['RIGHT_SHOULDER']['y']), 1, (255,0,255), 10)  # magenta\n",
    "    image = cv2.circle(image, (position['LEFT_WRIST']['x'], position['LEFT_WRIST']['y']), 1, (255,255,0), 10)  # yello\n",
    "    image = cv2.circle(image, (position['RIGHT_WRIST']['x'], position['RIGHT_WRIST']['y']), 1, (255,0,255), 10)  # magenta\n",
    "    \n",
    "    # color\n",
    "    RED = (0,0,255)\n",
    "    YELLO = (0,255,255)\n",
    "    MAGENTA = (255,0,255)\n",
    "    GREEN = (0,255,0)\n",
    "    BLUE = (255,0,0)\n",
    "\n",
    "    # draw circle\n",
    "    image = cv2.circle(image, (position['NOSE']['x'], position['NOSE']['y']), 1, RED, 10)  # red\n",
    "    image = cv2.circle(image, (position['LEFT_HIP']['x'], position['LEFT_HIP']['y']), 1, YELLO, 6)  # yello\n",
    "    image = cv2.circle(image, (position['RIGHT_HIP']['x'], position['RIGHT_HIP']['y']), 1, MAGENTA, 6)  # magenta\n",
    "    image = cv2.circle(image, (position['LEFT_SHOULDER']['x'], position['LEFT_SHOULDER']['y']), 1, YELLO, 10)  # yello\n",
    "    image = cv2.circle(image, (position['RIGHT_SHOULDER']['x'], position['RIGHT_SHOULDER']['y']), 1, MAGENTA, 10)  # magenta\n",
    "    image = cv2.circle(image, (position['LEFT_ELBOW']['x'], position['LEFT_ELBOW']['y']), 1, YELLO, 15)  # yello\n",
    "    image = cv2.circle(image, (position['RIGHT_ELBOW']['x'], position['RIGHT_ELBOW']['y']), 1, MAGENTA, 15)  # magenta\n",
    "    image = cv2.circle(image, (position['LEFT_WRIST']['x'], position['LEFT_WRIST']['y']), 1, YELLO, 20)  # yello\n",
    "    image = cv2.circle(image, (position['RIGHT_WRIST']['x'], position['RIGHT_WRIST']['y']), 1, MAGENTA, 20)  # magenta\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "#         plt.imshow(image)\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('image')\n",
    "        plt.show()\n",
    "        \n",
    "        pprint(position)      \n",
    "    return position\n",
    "\n",
    "\n",
    "def make_position2joint_angle(position, verbose=False):\n",
    "    joint_angle = {}\n",
    "    ##############################################################\n",
    "    ## 3점의 끼인각 구하기\n",
    "    # ex) p0 = [3.5, 6.7], p1 = [7.9, 8.4], p2 = [10.8, 4.8]\n",
    "\n",
    "    # 엉덩이-어깨-팔꿈치(LEFT)\n",
    "    a = 'LEFT_HIP'\n",
    "    b = 'LEFT_SHOULDER'\n",
    "    c = 'LEFT_ELBOW'\n",
    "\n",
    "    p0 = [position[a]['x'], position[a]['y']]\n",
    "    p1 = [position[b]['x'], position[b]['y']]\n",
    "    p2 = [position[c]['x'], position[c]['y']]\n",
    "    v0 = np.array(p0) - np.array(p1)\n",
    "    v1 = np.array(p2) - np.array(p1)\n",
    "    angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "    joint_angle['팔꿈치든각도_LEFT'] = -np.degrees(angle)\n",
    "\n",
    "    # 엉덩이-어깨-손목(LEFT)\n",
    "    a = 'LEFT_HIP'\n",
    "    b = 'LEFT_SHOULDER'\n",
    "    c = 'LEFT_WRIST'\n",
    "\n",
    "    p0 = [position[a]['x'], position[a]['y']]\n",
    "    p1 = [position[b]['x'], position[b]['y']]\n",
    "    p2 = [position[c]['x'], position[c]['y']]\n",
    "    v0 = np.array(p0) - np.array(p1)\n",
    "    v1 = np.array(p2) - np.array(p1)\n",
    "    angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "    joint_angle['손목든각도_LEFT'] = -np.degrees(angle)\n",
    "\n",
    "    # 엉덩이-어깨-팔꿈치(RIGHT)\n",
    "    a = 'RIGHT_HIP'\n",
    "    b = 'RIGHT_SHOULDER'\n",
    "    c = 'RIGHT_ELBOW'\n",
    "\n",
    "    p0 = [position[a]['x'], position[a]['y']]\n",
    "    p1 = [position[b]['x'], position[b]['y']]\n",
    "    p2 = [position[c]['x'], position[c]['y']]\n",
    "    v0 = np.array(p0) - np.array(p1)\n",
    "    v1 = np.array(p2) - np.array(p1)\n",
    "    angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "    joint_angle['팔꿈치든각도_RIGHT'] = np.degrees(angle)\n",
    "    \n",
    "    # 엉덩이-어깨-손목(RIGHT)\n",
    "    a = 'RIGHT_HIP'\n",
    "    b = 'RIGHT_SHOULDER'\n",
    "    c = 'RIGHT_WRIST'\n",
    "\n",
    "    p0 = [position[a]['x'], position[a]['y']]\n",
    "    p1 = [position[b]['x'], position[b]['y']]\n",
    "    p2 = [position[c]['x'], position[c]['y']]\n",
    "    v0 = np.array(p0) - np.array(p1)\n",
    "    v1 = np.array(p2) - np.array(p1)\n",
    "    angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "    joint_angle['손목든각도_RIGHT'] = np.degrees(angle)\n",
    "\n",
    "    # 어깨-팔꿈치-손목(LEFT)\n",
    "    a = 'LEFT_SHOULDER'\n",
    "    b = 'LEFT_ELBOW'\n",
    "    c = 'LEFT_WRIST'\n",
    "\n",
    "    p0 = [position[a]['x'], position[a]['y']]\n",
    "    p1 = [position[b]['x'], position[b]['y']]\n",
    "    p2 = [position[c]['x'], position[c]['y']]\n",
    "    v0 = np.array(p0) - np.array(p1)\n",
    "    v1 = np.array(p2) - np.array(p1)\n",
    "    angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "    joint_angle['팔꿈치굽힌각도_LEFT'] = np.degrees(angle)\n",
    "\n",
    "#     if joint_angle['팔꿈치굽힌각도_LEFT'] > 0:\n",
    "#         joint_angle['팔꿈치굽힌각도_LEFT'] = 180 - joint_angle['팔꿈치굽힌각도_LEFT']\n",
    "#     else:\n",
    "#         joint_angle['팔꿈치굽힌각도_LEFT'] = 180 + joint_angle['팔꿈치굽힌각도_LEFT']\n",
    "\n",
    "    # 어깨-팔꿈치-손목(RIGHT)\n",
    "    a = 'RIGHT_SHOULDER'\n",
    "    b = 'RIGHT_ELBOW'\n",
    "    c = 'RIGHT_WRIST'\n",
    "\n",
    "    p0 = [position[a]['x'], position[a]['y']]\n",
    "    p1 = [position[b]['x'], position[b]['y']]\n",
    "    p2 = [position[c]['x'], position[c]['y']]\n",
    "    v0 = np.array(p0) - np.array(p1)\n",
    "    v1 = np.array(p2) - np.array(p1)\n",
    "    angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "    joint_angle['팔꿈치굽힌각도_RIGHT'] = np.degrees(angle) - 180\n",
    "    \n",
    "#     if joint_angle['팔꿈치굽힌각도_RIGHT'] < 0:\n",
    "#         joint_angle['팔꿈치굽힌각도_RIGHT'] = joint_angle['팔꿈치굽힌각도_RIGHT'] + 180\n",
    "#     else:\n",
    "#         joint_angle['팔꿈치굽힌각도_RIGHT'] = 180 - joint_angle['팔꿈치굽힌각도_RIGHT']    \n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        pprint(joint_angle)\n",
    "        \n",
    "    return joint_angle\n",
    "\n",
    "    \n",
    "def make_command_from_skeleton(joint_angle, verbose=False):\n",
    "    ## 행동 조건으로 명령 생성\n",
    "    명령어 = [\n",
    "        '왼쪽으로가',\n",
    "        '오른쪽으로가',\n",
    "        '위로가',\n",
    "        '아래로가',\n",
    "        '앞으로가',\n",
    "        '뒤로가',\n",
    "        '돌아',\n",
    "        '뒤집어'    \n",
    "    ]\n",
    "    do_명령 = {}\n",
    "    for tmp in 명령어:\n",
    "        do_명령[tmp] = False\n",
    "\n",
    "    #################################################\n",
    "    ## 1) 왼쪽으로 가\n",
    "    # O\n",
    "    # |      \n",
    "    # |ㅡㅡㅡ|ㅡㅡㅡ\n",
    "    # |\n",
    "    # |\n",
    "    조건1 = (abs(joint_angle['팔꿈치굽힌각도_LEFT']) < 20)  # 팔꿈치 안굽히고\n",
    "    조건2 = (70 < joint_angle['손목든각도_LEFT']) and (joint_angle['손목든각도_LEFT'] < 110)  # 왼손 옆으로 쭉\n",
    "    if 조건1 and 조건2:\n",
    "        do_명령['왼쪽으로가'] =True\n",
    "    #################################################\n",
    "    ## 2) 오른쪽으로 가\n",
    "    #              O\n",
    "    #              |      \n",
    "    # ㅡㅡㅡ|ㅡㅡㅡ|\n",
    "    #              |\n",
    "    #              |\n",
    "    조건1 = (abs(joint_angle['팔꿈치굽힌각도_RIGHT']) < 20)  # 팔꿈치 안굽히고\n",
    "    조건2 = (70 < joint_angle['손목든각도_RIGHT']) and (joint_angle['손목든각도_RIGHT'] < 110)  # 왼손 옆으로 쭉\n",
    "    if 조건1 and 조건2:\n",
    "        do_명령['오른쪽으로가'] =True\n",
    "    #################################################\n",
    "    ## 3) 위로가, 왼팔을 팔꿈치를 90도정도 들고 손을 위로 들면 위로\n",
    "    # O      |\n",
    "    # |      |\n",
    "    # |ㅡㅡㅡ|\n",
    "    # |\n",
    "    # |\n",
    "    # 왼팔을 팔꿈치를 90도정도 들고 손을 위로 들면 위로\n",
    "    # 팔꿈치든각도_LEFT=98\n",
    "    # 손목든각도_LEFT=143\n",
    "    # 팔꿈치든각도_RIGHT=19\n",
    "    # 손목든각도_RIGHT=19\n",
    "    # 팔꿈치굽힌각도_LEFT=95\n",
    "    # 팔꿈치굽힌각도_RIGHT=1\n",
    "    조건1 = (abs(joint_angle['팔꿈치굽힌각도_LEFT']) > 70)  # 팔꿈치 굽히고\n",
    "    조건2 = (70 < joint_angle['팔꿈치든각도_LEFT']) and (joint_angle['팔꿈치든각도_LEFT'] < 110)  # 왼손 옆으로 쭉\n",
    "    if 조건1 and 조건2:\n",
    "        do_명령['위로가'] =True\n",
    "    #################################################\n",
    "    ## 5) 아래로 가, 왼팔을 팔꿈치를 90도정도 들고 손을 아래로 들면 위로\n",
    "    # O\n",
    "    # |      \n",
    "    # |ㅡㅡㅡ|\n",
    "    # |      |\n",
    "    # |      |\n",
    "    # 팔꿈치든각도_LEFT=76\n",
    "    # 손목든각도_LEFT=38\n",
    "    # 팔꿈치든각도_RIGHT=24\n",
    "    # 손목든각도_RIGHT=27\n",
    "    # 팔꿈치굽힌각도_LEFT=81\n",
    "    # 팔꿈치굽힌각도_RIGHT=7\n",
    "    조건1 = (abs(joint_angle['팔꿈치굽힌각도_LEFT']) > 70)  # 팔꿈치 굽히고\n",
    "    조건2 = (70 < joint_angle['팔꿈치든각도_LEFT']) and (joint_angle['팔꿈치든각도_LEFT'] < 110)  # 왼손 옆으로 쭉\n",
    "    if 조건1 and 조건2:\n",
    "        do_명령['아래로가'] =True\n",
    "    #################################################\n",
    "    ## 6) 앞으로가, 오른팔을 팔꿈치를 90도정도 들고 손을 위로 들면 위로\n",
    "    # |      O\n",
    "    # |      |\n",
    "    # |ㅡㅡㅡ|\n",
    "    #        |\n",
    "    #        |\n",
    "    조건1 = (abs(joint_angle['팔꿈치굽힌각도_RIGHT']) > 70)  # 팔꿈치 굽히고\n",
    "    조건2 = (70 < joint_angle['팔꿈치든각도_RIGHT']) and (joint_angle['팔꿈치든각도_RIGHT'] < 110)  # 왼손 옆으로 쭉\n",
    "    if 조건1 and 조건2:\n",
    "        do_명령['앞으로가'] =True\n",
    "    #################################################\n",
    "    ## 7) 뒤로가, 오른팔을 팔꿈치를 90도정도 들고 손을 아래로 들면 드론이 뒤로\n",
    "    #        O\n",
    "    #        |\n",
    "    # |ㅡㅡㅡ|\n",
    "    # |      |\n",
    "    # |      |\n",
    "    # 오른팔을 팔꿈치를 90도정도 들고 손을 아래로 내리면 위로\n",
    "    # 팔꿈치든각도_LEFT=17\n",
    "    # 손목든각도_LEFT=17\n",
    "    # 팔꿈치든각도_RIGHT=82\n",
    "    # 손목든각도_RIGHT=45\n",
    "    # 팔꿈치굽힌각도_LEFT=0\n",
    "    # 팔꿈치굽힌각도_RIGHT=282\n",
    "\n",
    "    조건1 = (abs(360 - joint_angle['팔꿈치굽힌각도_RIGHT']) > 70)  # 팔꿈치 굽히고\n",
    "    조건2 = (70 < joint_angle['팔꿈치든각도_RIGHT']) and (joint_angle['팔꿈치든각도_RIGHT'] < 110)  # 왼손 옆으로 쭉\n",
    "    if 조건1 and 조건2:\n",
    "        do_명령['뒤로가'] =True\n",
    "    #################################################\n",
    "    ## 8) 돌아, 양팔 아래 45도\n",
    "    # print(\"Rotate Clockwise\")\n",
    "    # 스피커(text='Move Down')        \n",
    "    # tello.rotate_clockwise(90)\n",
    "    #     | \n",
    "    #   / | \n",
    "    #    / \n",
    "    조건1 = (abs(joint_angle['팔꿈치굽힌각도_LEFT']) < 20)  # 팔꿈치 안굽히고\n",
    "    조건2 = (35 < joint_angle['팔꿈치든각도_LEFT']) and (joint_angle['팔꿈치든각도_LEFT'] < 65)  # 팔꿈치 왼쪽으로 45도\n",
    "    조건3 = (35 < joint_angle['손목든각도_LEFT']) and (joint_angle['손목든각도_LEFT'] < 65)  # 손목 왼쪽으로 45도\n",
    "    if 조건1 and 조건2 and 조건3:\n",
    "        do_명령['돌아'] =True\n",
    "    #################################################\n",
    "    ## 9) 뒤집어, 양팔 위로 45도\n",
    "    # print(\"Flip left\")\n",
    "    # 스피커(text='Move Down')        \n",
    "    # tello.flip_left()\n",
    "    #     | \n",
    "    #   \\ |\n",
    "    # 양팔 위 134도로 벌려\n",
    "    # 팔꿈치든각도_LEFT=133\n",
    "    # 손목든각도_LEFT=136\n",
    "    # 팔꿈치든각도_RIGHT=139\n",
    "    # 손목든각도_RIGHT=145\n",
    "    # 팔꿈치굽힌각도_LEFT=6\n",
    "    # 팔꿈치굽힌각도_RIGHT=11\n",
    "\n",
    "    조건1 = (abs(joint_angle['팔꿈치굽힌각도_LEFT']) < 20)  # 팔꿈치 안굽히고\n",
    "    조건2 = (abs(joint_angle['팔꿈치굽힌각도_RIGHT']) < 20)  # 팔꿈치 안굽히고\n",
    "    조건3 = (115 < joint_angle['팔꿈치든각도_LEFT']) and (joint_angle['팔꿈치든각도_LEFT'] < 155)  # 팔꿈치 왼쪽으로 135도\n",
    "    조건4 = (115 < joint_angle['손목든각도_LEFT']) and (joint_angle['손목든각도_LEFT'] < 155)  # 손목 왼쪽으로 135도\n",
    "    조건5 = (115 < joint_angle['팔꿈치든각도_RIGHT']) and (joint_angle['팔꿈치든각도_RIGHT'] < 155)  # 팔꿈치 왼쪽으로 135도\n",
    "    조건6 = (115 < joint_angle['손목든각도_RIGHT']) and (joint_angle['손목든각도_RIGHT'] < 155)  # 손목 왼쪽으로 135도\n",
    "\n",
    "    if 조건1 and 조건2 and 조건3 and 조건4 and 조건5 and 조건6:\n",
    "        do_명령['뒤집어'] =True\n",
    "\n",
    "    if verbose:\n",
    "        pprint(do_명령)\n",
    "    최종명령 = [key for key in do_명령.keys() if do_명령[key]==True]\n",
    "    print('명령 : %s'%최종명령)\n",
    "    return 최종명령, do_명령\n",
    "\n",
    "\n",
    "# position = make_mediapipe_result2position(image, results, verbose=verbose)\n",
    "# joint_angle = make_position2joint_angle(position, verbose=verbose)\n",
    "# 최종명령 = make_command_from_skeleton(joint_angle, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 이미지 한개 처리\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "# help(mp_pose.Pose)\n",
    "\n",
    "list_image_path = glob(os.path.join('example', '*.jpg'))  # ['./test1.jpg', './test2.jpg', ..]\n",
    "# list_image_path = ['./test1.jpg', './test2.jpg']\n",
    "image_path = list_image_path[1]\n",
    "\n",
    "verbose=True\n",
    "########################################\n",
    "# Run MediaPipe Pose and draw pose landmarks.\n",
    "with mp_pose.Pose(static_image_mode=True,\n",
    "                  min_detection_confidence=0.5,\n",
    "                  model_complexity=2) as pose:\n",
    "\n",
    "    ########################################\n",
    "#     image_path = './action8.jpg'\n",
    "\n",
    "    # Read images with OpenCV.\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    original_image = image.copy()\n",
    "    image_hight, image_width, _ = image.shape\n",
    "    ########################################\n",
    "    # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    ## util pose2명령\n",
    "    position = make_mediapipe_result2position(image, results, verbose=verbose)\n",
    "    joint_angle = make_position2joint_angle(position, verbose=verbose)\n",
    "    최종명령 = make_command_from_skeleton(joint_angle, verbose=True)\n",
    "    \n",
    "    \n",
    "# 오른쪽 아래가 302\n",
    "\n",
    "# 팔꿈치 왼쪽팔 위로: +100\n",
    "# 팔꿈치 왼쪽팔 아래: -100\n",
    "    \n",
    "# 팔꿈치 오른팔 위로: +100\n",
    "# 팔꿈치 오른팔 아래: 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 최종 명령 실행\n",
    "pprint(최종명령)\n",
    "key = 최종명령[0][0]\n",
    "\n",
    "print(key)\n",
    "\n",
    "# 드론 명령 실행\n",
    "if key == '앞으로가':\n",
    "    tello.move_forward(30)\n",
    "elif key == '뒤로가':\n",
    "    tello.move_back(30)\n",
    "elif key == '왼쪽으로가':\n",
    "    tello.move_left(30)\n",
    "elif key == '오른쪽으로가':\n",
    "    tello.move_right(30)\n",
    "elif key == '돌아':\n",
    "    tello.rotate_clockwise(30)\n",
    "elif key == '위로가':\n",
    "    tello.move_up(30)\n",
    "elif key == '아래로가':\n",
    "    tello.move_down(30)\n",
    "elif key == '착륙해':\n",
    "    tello.land()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 6.3) Face\n",
    "- [ref](https://google.github.io/mediapipe/solutions/face_detection)\n",
    "![](https://mediapipe.dev/images/mobile/face_detection_android_gpu.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare\n",
    "import mediapipe as mp\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "help(mp_face_detection.FaceDetection)\n",
    "\n",
    "# Prepare DrawingSpec for drawing the face landmarks later.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.3.1) mediapipe face detection with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check input image\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 이미지 크기 설정\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "\n",
    "# 이미지 resize 함수\n",
    "def resize_and_show(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image,\n",
    "                         (DESIRED_WIDTH, math.floor(h / (w / DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(\n",
    "            image, (math.floor(w / (h / DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "\n",
    "\n",
    "#     cv2.imshow('image', img)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('image')\n",
    "    plt.show()\n",
    "\n",
    "list_image_path = glob(os.path.join(\n",
    "    'example', '*.jpg'))  # ['./test1.jpg', './test2.jpg', ..]\n",
    "# list_image_path = ['./test1.jpg', './test2.jpg']\n",
    "\n",
    "# Read images with OpenCV.\n",
    "images = {name: cv2.imread(name) for name in list_image_path}\n",
    "# Preview the images.\n",
    "for name, image in images.items():\n",
    "    print(name)\n",
    "    resize_and_show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run MediaPipe Face Detection with short range model.\n",
    "with mp_face_detection.FaceDetection(min_detection_confidence=0.5,\n",
    "                                     model_selection=1) as face_detection:\n",
    "    for name, image in images.items():\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "        results = face_detection.process(cv2.cvtColor(image,\n",
    "                                                      cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw face detections of each face.\n",
    "        print(f'Face detections of {name}:')\n",
    "        if not results.detections:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        for detection in results.detections:\n",
    "            mp_drawing.draw_detection(annotated_image, detection)\n",
    "        resize_and_show(annotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.3.2) mediapipe face detection with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mediapipe face detection with webcam\n",
    "# select camera type\n",
    "camera_type = 'notebook'\n",
    "# camera_type = 'webcam'\n",
    "\n",
    "if camera_type == 'notebook':\n",
    "    camera_idx = 0\n",
    "elif camera_type == 'webcam':\n",
    "    camera_idx = 1\n",
    "else:\n",
    "    assert 'select camera type'\n",
    "\n",
    "# prepare\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "# Prepare DrawingSpec for drawing the face landmarks later.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(camera_idx)\n",
    "\n",
    "# Run MediaPipe Face Detection with short range model.\n",
    "# model_selection_idx = 0  # 카메라 2m 이내의 부분적 모델 촬영에 적합\n",
    "model_selection_idx = 1  # 5m 이내의 전신 모델을 촬영하는데 적합\n",
    "with mp_face_detection.FaceDetection(\n",
    "        min_detection_confidence=0.5,\n",
    "        model_selection=model_selection_idx) as face_detection:\n",
    "\n",
    "    print('open webcam & run pose')\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image)\n",
    "\n",
    "        # Draw the face detection annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(image, detection)\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "        # esc 키 종료\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.3.3) mediapipe face mesh with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check input image\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 이미지 크기 설정\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "\n",
    "# 이미지 resize 함수\n",
    "def resize_and_show(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image,\n",
    "                         (DESIRED_WIDTH, math.floor(h / (w / DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(\n",
    "            image, (math.floor(w / (h / DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "\n",
    "\n",
    "#     cv2.imshow('image', img)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mediapipe face mesh image\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "list_image_path = glob(os.path.join('example', '*.jpg'))  # ['./test1.jpg', './test2.jpg', ..]\n",
    "# list_image_path = ['./test1.jpg', './test2.jpg']\n",
    "\n",
    "images = {name: cv2.imread(name) for name in list_image_path}\n",
    "\n",
    "# Run MediaPipe Face Detection with short range model.\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=True,\n",
    "                           max_num_faces=1,\n",
    "                           refine_landmarks=True,\n",
    "                           min_detection_confidence=0.5) as face_mesh:\n",
    "\n",
    "    for name, image in images.items():\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw face detections of each face.\n",
    "        print(f'Face mesh of {name}:')\n",
    "        if not results.multi_face_landmarks:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=annotated_image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles.\n",
    "                get_default_face_mesh_tesselation_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=annotated_image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles.\n",
    "                get_default_face_mesh_contours_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=annotated_image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles.\n",
    "                get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "        resize_and_show(annotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.3.4) mediapipe face mesh with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mediapipe face mesh with webcam\n",
    "# select camera type\n",
    "camera_type = 'notebook'\n",
    "# camera_type = 'webcam'\n",
    "\n",
    "if camera_type == 'notebook':\n",
    "    camera_idx = 0\n",
    "elif camera_type == 'webcam':\n",
    "    camera_idx = 1\n",
    "else:\n",
    "    assert 'select camera type'\n",
    "\n",
    "# prepare\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(camera_idx)\n",
    "\n",
    "# Run MediaPipe Face mesh model\n",
    "with mp_face_mesh.FaceMesh(max_num_faces=1,\n",
    "                           refine_landmarks=True,\n",
    "                           min_detection_confidence=0.5,\n",
    "                           min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    print('open webcam & run pose')\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"can not find camera\")\n",
    "            break\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # 이미지 위에 얼굴 그물망 주석을 그립니다.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.\n",
    "                    get_default_face_mesh_tesselation_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.\n",
    "                    get_default_face_mesh_contours_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.\n",
    "                    get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Face Mesh(Puleugo)', cv2.flip(image, 1))\n",
    "        # esc 키 종료\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 6.4) hand\n",
    "- [ref](https://google.github.io/mediapipe/solutions/hands)\n",
    "![](https://mediapipe.dev/images/mobile/hand_landmarks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.4.1) mediapipe hand detection with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# util\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 이미지 크기 설정\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "\n",
    "# 이미지 resize 함수\n",
    "def resize_and_show(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image,\n",
    "                         (DESIRED_WIDTH, math.floor(h / (w / DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(\n",
    "            image, (math.floor(w / (h / DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "\n",
    "\n",
    "#     cv2.imshow('image', img)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## mediapipe hand detection with image\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils  # 핸드 이미지 위에 랜드 마크 그리기 위함\n",
    "mp_drawing_styles = mp.solutions.drawing_styles  # 핸드 처리 \n",
    "mp_hands = mp.solutions.hands  # 핸드 랜드마크 표시 스타일용\n",
    "\n",
    "list_image_path = glob(os.path.join('example', 'hand*.jpg'))  # ['./test1.jpg', './test2.jpg', ..]\n",
    "# list_image_path = ['./test1.jpg', './test2.jpg']\n",
    "\n",
    "images = {name: cv2.imread(name) for name in list_image_path}\n",
    "\n",
    "\n",
    "with mp_hands.Hands(static_image_mode=True,\n",
    "                    max_num_hands=2,\n",
    "                    min_detection_confidence=0.5) as hands:\n",
    "    \n",
    "    for name, image in images.items():\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print handedness and draw hand landmarks on the image.\n",
    "        print('Handedness:', results.multi_handedness)\n",
    "        if not results.multi_hand_landmarks:\n",
    "            continue\n",
    "        image_height, image_width, _ = image.shape\n",
    "        annotated_image = image.copy()\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            print('hand_landmarks:', hand_landmarks)\n",
    "            print(\n",
    "                f'Index finger tip coordinates: (',\n",
    "                f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "                f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "            )\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "        \n",
    "        \n",
    "        resize_and_show(annotated_image)\n",
    "        # Draw hand world landmarks.\n",
    "        if not results.multi_hand_world_landmarks:\n",
    "            continue\n",
    "        for hand_world_landmarks in results.multi_hand_world_landmarks:\n",
    "            mp_drawing.plot_landmarks(hand_world_landmarks,\n",
    "                                      mp_hands.HAND_CONNECTIONS,\n",
    "                                      azimuth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 6.4.2) mediapipe hand detection with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## mediapipe hand detection with webcam\n",
    "# select camera type\n",
    "camera_type = 'notebook'\n",
    "# camera_type = 'webcam'\n",
    "\n",
    "if camera_type == 'notebook':\n",
    "    camera_idx = 0\n",
    "elif camera_type == 'webcam':\n",
    "    camera_idx = 1\n",
    "else:\n",
    "    assert 'select camera type'\n",
    "    \n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils  # 핸드 이미지 위에 랜드 마크 그리기 위함\n",
    "mp_drawing_styles = mp.solutions.drawing_styles  # 핸드 처리 \n",
    "mp_hands = mp.solutions.hands  # 핸드 랜드마크 표시 스타일용\n",
    "\n",
    "# For webcam input:\n",
    "print('start webcam')\n",
    "cap = cv2.VideoCapture(camera_type)  # 웹캠 열기\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    "with mp_hands.Hands(model_complexity=0,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            # 에러 출력 후 루프 시작으로 되돌아감\n",
    "            # 카메라 로딩중일 수 있기때문에 break대신 continue로 함\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False  # 성능 향상을 위해 이미지를 쓰기 불가시켜 참조로 전달\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)  # 손가락 마디 검출\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True  # 다시 이미지를 쓰기 가능으로 변경\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # RGB에서 BGR로 변경\n",
    "        if results.multi_hand_landmarks:\n",
    "            # 랜드마크 숫자 만큼 루프\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # 이미지에 랜드마크 위치마다 표시\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "        # 5ms 대기하면서 키보드 입력 대기\n",
    "        # 27 > ESC 키  \n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
